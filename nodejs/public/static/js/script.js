// HTML ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
const videoElement = document.getElementById("webcam-video");
const canvasElement = document.getElementById("landmark-canvas");
const canvasCtx = canvasElement.getContext("2d");
const statusElement = document.getElementById("status");

// MediaPipe ëª¨ë¸ ì´ˆê¸°í™” ìƒíƒœì™€ ë¹„ë””ì˜¤ ì¬ìƒ ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ì „ì—­ í”Œë˜ê·¸
let isFaceMeshInitialized = false;
let isVideoPlaying = false;
let lastDetectionTime = 0; // ë§ˆì§€ë§‰ ê°ì§€ ì‹œê°„
const detectionInterval = 1000; // 1ì´ˆ (1000ms) ê°„ê²©ìœ¼ë¡œ ëœë“œë§ˆí¬ ê°ì§€

// ì„œë²„ ì „ì†¡ ê´€ë ¨ ë³€ìˆ˜
const featuresBuffer = [];

// íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
function getDistance(p1, p2) {
    return Math.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2);
}

function getEAR(eyeLandmarks) {
    const verDist1 = getDistance(eyeLandmarks[1], eyeLandmarks[5]);
    const verDist2 = getDistance(eyeLandmarks[2], eyeLandmarks[4]);
    const horDist = getDistance(eyeLandmarks[0], eyeLandmarks[3]);
    const ear = (verDist1 + verDist2) / (2.0 * horDist);
    return ear;
}

// MediaPipe FaceMesh ì„¤ì •
const faceMesh = new FaceMesh({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
});

faceMesh.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true,
    minDetectionConfidence: 0.3,
    minTrackingConfidence: 0.5,
    modelComplexity: 0,
});

faceMesh.onResults(onResults);

// âœ¨ ìˆ˜ì • 1: í•¨ìˆ˜ì˜ ê°€ì¥ ì²« ì¤„ì— í…ŒìŠ¤íŠ¸ ë¡œê·¸ ì¶”ê°€
async function initializeWebcamAndMediaPipeProcessing() {
    console.log("í…ŒìŠ¤íŠ¸ 2ë²ˆ - ì›¹ìº  í•¨ìˆ˜ ì§„ì…"); // í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¡œê·¸ ë©”ì‹œì§€ ìˆ˜ì •
    
    statusElement.textContent = "ì›¹ìº  í™œì„±í™” ìš”ì²­ ì¤‘...";

    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        const msg = "ğŸš¨ ë¸Œë¼ìš°ì €ê°€ ì›¹ìº  API(getUserMedia)ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.";
        console.error(msg);
        statusElement.textContent = msg;
        return;
    }

    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: { width: 640, height: 480 },
            audio: false,
        });
        videoElement.srcObject = stream;
        await new Promise((resolve) => {
            videoElement.onloadedmetadata = () => {
                videoElement.play();
                videoElement.style.display = "block";
                resolve();
            };
        });
        videoElement.addEventListener("playing", () => {
            isVideoPlaying = true;
            if (isFaceMeshInitialized) {
                sendFramesToMediaPipe();
            }
        }, { once: true });
    } catch (error) {
        let customErrorMessage = `ì›¹ìº  í™œì„±í™” ì‹¤íŒ¨: ${error.name || "UnknownError"}`;
        // ... (ì´í•˜ ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€ ë¶€ë¶„ì€ ê¸°ì¡´ê³¼ ë™ì¼)
        statusElement.textContent = `ğŸš¨ ${customErrorMessage}`;
        console.error("ğŸ”´ ì›¹ìº  í™œì„±í™” ì¹˜ëª…ì ì¸ ì‹¤íŒ¨:", error);
    }
}

// MediaPipeì— í”„ë ˆì„ ì „ì†¡ ë£¨í”„
async function sendFramesToMediaPipe() {
    if (!isFaceMeshInitialized || !isVideoPlaying) {
        setTimeout(sendFramesToMediaPipe, detectionInterval);
        return;
    }
    if (videoElement.paused || videoElement.ended) {
        return;
    }
    const now = performance.now();
    if (now - lastDetectionTime >= detectionInterval) {
        if (videoElement.videoWidth > 0) {
            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            await faceMesh.send({ image: videoElement });
            lastDetectionTime = now;
        }
    }
    setTimeout(sendFramesToMediaPipe, 100);
}

// MediaPipe ê²°ê³¼ ì²˜ë¦¬ í•¨ìˆ˜
function onResults(results) {
    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

    if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const faceLandmarks = results.multiFaceLandmarks[0];
        const LEFT_EYE_INDICES = [362, 385, 387, 263, 373, 380];
        const RIGHT_EYE_INDICES = [33, 160, 158, 133, 153, 144];
        const leftEye = LEFT_EYE_INDICES.map(i => faceLandmarks[i]);
        const rightEye = RIGHT_EYE_INDICES.map(i => faceLandmarks[i]);
        const earLeft = getEAR(leftEye);
        const earRight = getEAR(rightEye);
        const features = {
            timestamp: new Date().toISOString(),
            ear_left: earLeft,
            ear_right: earRight
        };
        featuresBuffer.push(features);
        console.log(`ğŸ”µ EAR Left: ${earLeft.toFixed(3)}, EAR Right: ${earRight.toFixed(3)}`);
        statusElement.textContent = `ğŸŸ¢ íŠ¹ì§• ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (${featuresBuffer.length}ê°œ)`;
    } else {
        statusElement.textContent = "ì–¼êµ´ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤... (ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ ì£¼ì„¸ìš”)";
    }
    canvasCtx.restore();
}

// âœ¨ ìˆ˜ì • 2: ë§¨ ì•„ë˜ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆë¥¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ êµì²´
document.addEventListener("DOMContentLoaded", () => {
    console.log("í…ŒìŠ¤íŠ¸ 1ë²ˆ");
    initializeWebcamAndMediaPipeProcessing(); // async/await ì—†ì´ í˜¸ì¶œ
    console.log("í…ŒìŠ¤íŠ¸ 3ë²ˆ");
    
    // MediaPipe ëª¨ë¸ ì´ˆê¸°í™”ëŠ” ê·¸ëŒ€ë¡œ ì§„í–‰
    faceMesh.initialize().then(() => {
        isFaceMeshInitialized = true;
        console.log("ğŸŸ¢ isFaceMeshInitialized í”Œë˜ê·¸ê°€ TRUEë¡œ ì„¤ì •ë¨.");
        if (isVideoPlaying) {
            sendFramesToMediaPipe();
        }
    });
});